{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gisSEwlud_Yn"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "import string\n",
    "from time import strftime\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import ParameterGrid, cross_validate\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.utils.io.Tee at 0x7f305473faf0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.utils.io import Tee\n",
    "\n",
    "# Redirect all the outputs messages to the terminal and to a log file\n",
    "logs_dir = './logs'\n",
    "logfilename = logs_dir + strftime('/ipython_%Y-%m-%d_%H:%M:%S') + '.log' \n",
    "if not os.path.exists(logs_dir):\n",
    "    os.makedirs(logs_dir)\n",
    "    \n",
    "sys.stdout = open('/dev/stdout', 'w')\n",
    "Tee(logfilename, mode='w', channel='stdout')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "\n",
    "JOINT = 'Knee'\n",
    "FORCE_CELLS_PER_JOINT = {\n",
    "    'Hip': [5, 6],\n",
    "    'Knee': [3, 4, 7, 8],\n",
    "    'Ankle': [1, 2]\n",
    "}\n",
    "\n",
    "CELLS = FORCE_CELLS_PER_JOINT[JOINT]\n",
    "\n",
    "# Directory where the derived data is stored\n",
    "DERIVED_DATA_DIR = '../../../../data'\n",
    "# Path where the results are stored\n",
    "RESULTS_PATH = '../../../../results'\n",
    "# Total number of experiments\n",
    "N_EXPERIMENTS = 63\n",
    "# Number of folds for cross-validation\n",
    "CV = 6\n",
    "# Experiments for training set (int)\n",
    "TRAIN_SIZE = 54\n",
    "# Experiments for test set (int)\n",
    "TEST_SIZE = 9\n",
    "\n",
    "# ID of the training and validation data resulting from this notebook, stored in RESULTS_PATH\n",
    "DATA_ID = '0012_09082021'\n",
    "# Hyperparameters search date\n",
    "hs_date = '16082021'\n",
    "\n",
    "# Parameters grid\n",
    "param_grid = {\n",
    "    'sequence_len': [5, 10, 20, 30, 50],\n",
    "    'hidden_dim': [8, 16, 32],\n",
    "    'sigma': [0.8, 1],\n",
    "    'n_layers': [1, 2, 3]\n",
    "}\n",
    "\n",
    "TORCH_DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', TORCH_DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_dirs_path = glob.glob(DERIVED_DATA_DIR + '/*/*')\n",
    "print('Number of experiments:', len(experiments_dirs_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of experiments: 40\n"
     ]
    }
   ],
   "source": [
    "# Experiment selection (optional)\n",
    "experiments_dirs_path_filter = []\n",
    "\n",
    "exp_params = {}\n",
    "for exp_path in experiments_dirs_path:\n",
    "    with open(exp_path + '/parameters.json') as f:\n",
    "        exp_params[exp_path] = json.load(f)\n",
    "        \n",
    "    if int(exp_params[exp_path]['SkinConfig']) == 0 or exp_params[exp_path]['SkinConfig'] == 'NaN':\n",
    "        experiments_dirs_path_filter.append(exp_path)\n",
    "        \n",
    "print('Final number of experiments:', len(experiments_dirs_path_filter))\n",
    "experiments_dirs_path = experiments_dirs_path_filter\n",
    "\n",
    "# Redefine the split of the data for the filtered experiments\n",
    "\n",
    "# Total number of experiments\n",
    "N_EXPERIMENTS = 40\n",
    "# Number of folds for cross-validation\n",
    "CV = 4\n",
    "# Experiments for training set (int)\n",
    "TRAIN_SIZE = 32\n",
    "# Experiments for test set (int)\n",
    "TEST_SIZE = 8\n",
    "\n",
    "assert(TRAIN_SIZE + TEST_SIZE == N_EXPERIMENTS)\n",
    "assert(TRAIN_SIZE % CV == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "H3_LEG = 'L' # L|R\n",
    "\n",
    "# features = [H3_LEG + a + m for a in ['Hip', 'Knee', 'Ankle'] for m in ['Pos', 'Vel', 'Acc', 'Torque']] + ['LegKnee{}Filtered'.format(m) for m in ['Position', 'Velocity', 'Torque']]\n",
    "# targets = ['F' + str(i + 1) + ax for i in range(N_CELLS) for ax in ['x', 'y', 'z']]\n",
    "features = ['L{}Pos'.format(JOINT)] + ['F' + str(i) + 'z' for i in FORCE_CELLS_PER_JOINT[JOINT]]\n",
    "targets = ['F' + str(i) + ax for i in FORCE_CELLS_PER_JOINT[JOINT] for ax in ['x', 'y']]\n",
    "\n",
    "print('Number of features: {}'.format(len(features)))\n",
    "print('Selected features: {}'.format(features))\n",
    "print('\\n')\n",
    "print('Number of targets: {}'.format(len(targets)))\n",
    "print('Selected targets: {}'.format(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "targets_dict = {}\n",
    "features_dict = {}\n",
    "for i, exp_path in enumerate(experiments_dirs_path):\n",
    "    print('{} - Experiment {} from {}'.format(i, exp_path.split('/')[-1], exp_path.split('/')[-2]))\n",
    "    \n",
    "    # Load targets\n",
    "    targets_df = pd.read_csv(exp_path + '/force_cells_processed.csv')\n",
    "    \n",
    "    # Load features\n",
    "    exo_df = pd.read_csv(exp_path + '/H3_processed.csv')\n",
    "    # leg_df = pd.read_csv(exp_path + '/leg_processed.csv')\n",
    "    # features_df = pd.concat([exo_df, leg_df], axis=1)\n",
    "    features_df = exo_df\n",
    "    \n",
    "    idx_aux = targets_df.duplicated(keep='first')\n",
    "    targets_df = targets_df.loc[~idx_aux]\n",
    "    features_df = features_df.loc[~idx_aux]\n",
    "    print('Droping {} duplicated data points'.format(len(idx_aux[idx_aux == False])))\n",
    "    \n",
    "    # Drop first row to remove noise in the start of the data recording\n",
    "    targets_df = targets_df.iloc[1:]\n",
    "    features_df = features_df.iloc[1:]\n",
    "    # Drop null values\n",
    "    idx = features_df.notna().all(axis=1)\n",
    "    features_df = features_df.loc[idx]\n",
    "    targets_df = targets_df.loc[idx]\n",
    "    print('Droping {} data points by null features'.format(len(idx[idx == False])))\n",
    "\n",
    "    assert(len(features_df) == len(targets_df))\n",
    "    data_df = pd.concat([features_df, targets_df], axis=1)\n",
    "    \n",
    "    # Store the final array\n",
    "    targets_dict[i] = data_df[targets].values\n",
    "    features_dict[i] = data_df[features].values\n",
    "    \n",
    "    print('Experiment {} -> X: {}, Y: {} \\n'.format(i, features_dict[i].shape, targets_dict[i].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = list(range(N_EXPERIMENTS))\n",
    "random.shuffle(experiments)\n",
    "\n",
    "train_experiments = experiments[:TRAIN_SIZE]\n",
    "test_experiments = experiments[TRAIN_SIZE:]\n",
    "\n",
    "print('Train experiments ids ({}): {}'.format(len(train_experiments), train_experiments))\n",
    "print('Test experiments ids ({}): {}'.format(len(test_experiments), test_experiments))\n",
    "\n",
    "assert(len(train_experiments) + len(test_experiments) == N_EXPERIMENTS)\n",
    "# Check that no test experiment is in train\n",
    "assert(not any([i in test_experiments for i in train_experiments]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM hyperparameters search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):      \n",
    "    def __init__(self, input_size, hidden_dim, sigma, output_size, sequence_len, num_iter, n_layers, device, lr=0.001, batch_size=32, early_stopping_patience=10):\n",
    "        \n",
    "        # input size -> Dimension of the input signal\n",
    "        # outpusize -> Dimension of the output signal\n",
    "        # hidden_dim -> Dimension of the rnn state\n",
    "        # n_layers -> If >1, we are using a stacked RNN\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_size = input_size\n",
    "        self.sigma = sigma\n",
    "        self.output_size = output_size\n",
    "        self.sequence_length = sequence_len\n",
    "        self.num_layers = n_layers\n",
    "        \n",
    "        # define an LSTM with specified parameters\n",
    "        # batch_first=True means that the first dimension of the input will be the batch_size\n",
    "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_dim, num_layers=n_layers, batch_first=True, dropout=0.3)\n",
    "        \n",
    "        # last, fully-connected layer\n",
    "        self.fc1 = nn.Linear(hidden_dim, output_size) \n",
    "        \n",
    "        self.lr = lr #Learning Rate\n",
    "        self.batch_size = batch_size\n",
    "        self.optim = optim.Adam(self.parameters(), self.lr)\n",
    "        self.num_iter = num_iter\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.criterion = nn.MSELoss()     \n",
    "        \n",
    "        self.device = device\n",
    "        self.to(self.device)\n",
    "        \n",
    "        # A list to store the loss evolution along training\n",
    "        self.loss_during_training = [] \n",
    "        self.valid_loss_during_training = []\n",
    "        \n",
    "    def forward(self, x, h0=None):\n",
    "        \n",
    "        '''\n",
    "        About the shape of the different tensors ...:\n",
    "        \n",
    "        - Input signal x has shape (batch_size, seq_length, input_size)\n",
    "        - The initialization of the RNN hidden state h0 has shape (n_layers, batch_size, hidden_dim).\n",
    "          If None value is used, internally it is initialized to zeros.\n",
    "        - The RNN output (batch_size, seq_length, hidden_size). This output is the RNN state along time  \n",
    "\n",
    "        '''\n",
    "        batch_size = x.size(0) # Number of signals N\n",
    "        seq_length = x.size(1) # T\n",
    "        \n",
    "        # get RNN outputs\n",
    "        # r_out is the sequence of states\n",
    "        # hidden is just the last state (we will use it for forecasting)\n",
    "        #print(x.shape)\n",
    "        r_out, hidden = self.rnn(x, h0)\n",
    "        #print(r_out.shape, hidden.shape)\n",
    "        \n",
    "        # shape r_out to be (seq_length, hidden_dim)     \n",
    "        r_out = r_out.reshape(-1, self.hidden_dim) \n",
    "        #print(r_out.shape)\n",
    "        \n",
    "        output = self.fc1(r_out)\n",
    "        #print(output.shape)\n",
    "        \n",
    "        noise = torch.randn_like(output) * self.sigma\n",
    "        \n",
    "        output += noise\n",
    "        \n",
    "        # reshape back to temporal structure\n",
    "        output = output.reshape([-1, self.sequence_length, 1])\n",
    "\n",
    "        return output, hidden\n",
    "           \n",
    "    def trainloop(self, x, y, x_val=None, y_val=None):\n",
    "        \n",
    "        # SGD Loop\n",
    "        for e in range(int(self.num_iter)):\n",
    "        \n",
    "            running_loss = 0.\n",
    "            \n",
    "            idx = list(range(x.shape[0]))\n",
    "            random.shuffle(idx)\n",
    "            \n",
    "            batchs = [idx[i:i + self.batch_size] for i in range(0, x.shape[0], self.batch_size)]\n",
    "            for b in batchs:\n",
    "\n",
    "                features = x[b, :, :]\n",
    "                target = y[b, :, :]\n",
    "\n",
    "                # print(features.shape, target.shape)\n",
    "                self.optim.zero_grad() \n",
    "                \n",
    "                features = torch.Tensor(features).to(self.device)  \n",
    "                target = torch.Tensor(target).to(self.device)\n",
    "                \n",
    "                out,hid = self.forward(features)\n",
    "\n",
    "                # print(out.shape, hid.shape, target.shape)\n",
    "                # print(out[:, -1, 0].size(), target[:, 0].size())\n",
    "                loss = self.criterion(out[:, -1, 0], target[:, -1, 0]) \n",
    "                running_loss += loss.item()\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                # This code helps to avoid vanishing exploiting gradients in RNNs\n",
    "                # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "                nn.utils.clip_grad_norm_(self.parameters(), 2.0)\n",
    "\n",
    "                self.optim.step()\n",
    "                \n",
    "            self.loss_during_training.append(running_loss / len(batchs))\n",
    "            \n",
    "            if x_val is not None and y_val is not None:\n",
    "                with torch.no_grad():\n",
    "                    # Set the model in evaluation mode \n",
    "                    self.eval()\n",
    "\n",
    "                    running_loss_val = 0.\n",
    "                    idx = list(range(x_val.shape[0]))\n",
    "\n",
    "                    batchs = [idx[i:i + self.batch_size] for i in range(0, x_val.shape[0], self.batch_size)]\n",
    "                    for b in batchs:\n",
    "                        features = x_val[b, :, :]\n",
    "                        target = y_val[b, :, :]\n",
    "\n",
    "                        features = torch.Tensor(features).to(self.device) #YOUR CODE HERE  \n",
    "                        target = torch.Tensor(target).to(self.device) #YOUR CODE HERE  \n",
    "\n",
    "                        out,hid = self.forward(features)\n",
    "\n",
    "                        # print(out.shape, hid.shape, target.shape)\n",
    "                        # print(out[:, -1, 0].size(), target[:, -1, 0].size())\n",
    "                        loss = self.criterion(out[:, -1, 0], target[:, -1, 0]) #YOUR CODE HERE\n",
    "                        running_loss_val += loss.item()\n",
    "\n",
    "                    self.valid_loss_during_training.append(running_loss_val / len(splits))\n",
    "\n",
    "                # Return the model to training mode\n",
    "                self.train()\n",
    "\n",
    "                print(\"%d epochs -> Train loss: %f - Val loss: %f\"%(e, self.loss_during_training[-1], self.valid_loss_during_training[-1]))\n",
    "                    \n",
    "                if len(self.valid_loss_during_training) > self.early_stopping_patience + 1:\n",
    "                    if self.valid_loss_during_training[-1] > np.mean(self.valid_loss_during_training[-self.early_stopping_patience:]):\n",
    "                        print('Early stopping at epoch', e + 1)\n",
    "                        return e\n",
    "            else:\n",
    "                print(\"%d epochs -> Train loss: %f\"%(e, self.loss_during_training[-1]))\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/hl0d0w1g/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e46ef9c2a801>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mt_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mlast_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mtr_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mearly_stopping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-10ba03ae81c2>\u001b[0m in \u001b[0;36mtrainloop\u001b[0;34m(self, x, y, x_val, y_val)\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;31m# This code helps to avoid vanishing exploiting gradients in RNNs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/EducaciÃ³n/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid_ls = list(ParameterGrid(param_grid))\n",
    "random.shuffle(param_grid_ls)\n",
    "param_grid_len = len(param_grid_ls)\n",
    "print('Number of parameters combinations: {}'.format(param_grid_len))\n",
    "\n",
    "for idx, params in enumerate(param_grid_ls):\n",
    "    params_id = ''.join(random.choices(string.ascii_uppercase + string.digits, k=10))\n",
    "    print('Parameters ({}) {}/{}  -  {}'.format(params_id, idx + 1, param_grid_len, strftime('%Y-%m-%d %H:%M:%S')))\n",
    "    print(params)\n",
    "    \n",
    "    # Prepare sequences\n",
    "    X_train, Y_train = [], [] \n",
    "    for i in train_experiments:\n",
    "        X_aux = features_dict[i]\n",
    "        Y_aux = targets_dict[i]\n",
    "\n",
    "        splits = [i for i in range(0, X_aux.shape[0], params['sequence_len'])]\n",
    "\n",
    "        X_tensor = np.zeros([len(splits), params['sequence_len'], len(features)])\n",
    "        Y_tensor = np.zeros([len(splits), params['sequence_len'], len(targets)])\n",
    "\n",
    "        for idx, i in enumerate(splits[:-1]):\n",
    "            X_tensor[idx, :, :] = X_aux[splits[idx]:splits[idx + 1], :]\n",
    "            Y_tensor[idx, :, :] = Y_aux[splits[idx + 1] - 1, :]\n",
    "\n",
    "        # print(X_tensor.shape)\n",
    "        # print(Y_tensor.shape)\n",
    "\n",
    "        X_train.append(X_tensor)\n",
    "        Y_train.append(Y_tensor)\n",
    "\n",
    "    X_train, Y_train = np.concatenate(X_train, axis=0), np.concatenate(Y_train, axis=0) \n",
    "\n",
    "\n",
    "    X_test, Y_test = [], [] \n",
    "    for i in test_experiments:\n",
    "        X_aux = features_dict[i]\n",
    "        Y_aux = targets_dict[i]\n",
    "\n",
    "        splits = [i for i in range(0, X_aux.shape[0], params['sequence_len'])]\n",
    "\n",
    "        X_tensor = np.zeros([len(splits), params['sequence_len'], len(features)])\n",
    "        Y_tensor = np.zeros([len(splits), params['sequence_len'], len(targets)])\n",
    "\n",
    "        for idx, i in enumerate(splits[:-1]):\n",
    "            X_tensor[idx, :, :] = X_aux[splits[idx]:splits[idx + 1], :]\n",
    "            Y_tensor[idx, :, :] = Y_aux[splits[idx + 1] - 1, :]\n",
    "\n",
    "        # print(X_tensor.shape)\n",
    "        # print(Y_tensor.shape)\n",
    "\n",
    "        X_test.append(X_tensor)\n",
    "        Y_test.append(Y_tensor)\n",
    "\n",
    "    X_test, Y_test = np.concatenate(X_test, axis=0), np.concatenate(Y_test, axis=0) \n",
    "\n",
    "    X_train_norm = np.zeros(list(X_train.shape))\n",
    "    X_test_norm = np.zeros(list(X_test.shape))\n",
    "\n",
    "    scalers = []\n",
    "    for f in range(len(features)):\n",
    "        s = MinMaxScaler().fit(X_train[:, :, f])\n",
    "\n",
    "        scalers.append(s)\n",
    "\n",
    "        X_train_norm[:, :, f] = s.transform(X_train[:, :, f])\n",
    "        X_test_norm[:, :, f] = s.transform(X_test[:, :, f])\n",
    "\n",
    "\n",
    "    results = defaultdict(list)\n",
    "    tr_time = []\n",
    "    early_stopping = []\n",
    "    for t in range(Y_train.shape[2]):\n",
    "\n",
    "        model = LSTM(input_size=X_train_norm.shape[2], output_size=1, num_iter=50, device=TORCH_DEVICE, **params)\n",
    "\n",
    "        t_start = time.time()\n",
    "        last_epoch = model.trainloop(X_train_norm, Y_train[:, :, t:t+1], X_test_norm, Y_test[:, :, t:t+1])\n",
    "        tr_time.append(time.time() - t_start)\n",
    "        early_stopping.append(last_epoch)\n",
    "\n",
    "        all_results = {'MAE': [], 'MSE': [], 'R2': []}\n",
    "        for i in test_experiments:\n",
    "            X_aux = features_dict[i]\n",
    "            Y_aux = targets_dict[i]\n",
    "\n",
    "            true = []\n",
    "            pred = []\n",
    "\n",
    "            for i in range(params['sequence_len'], X_aux.shape[0]):\n",
    "                X_aux_ = X_aux[np.newaxis, i-params['sequence_len']:i, :]\n",
    "                for f in range(len(features)):\n",
    "                    s = scalers[f]\n",
    "\n",
    "                    X_aux_[:, :, f] = s.transform(X_aux_[:, :, f])\n",
    "\n",
    "                features_ = torch.Tensor(X_aux_).to(TORCH_DEVICE)\n",
    "                target_ = torch.Tensor(Y_aux[np.newaxis, i, t:t+1]).to(TORCH_DEVICE)\n",
    "\n",
    "                out, hid = model.forward(features_)\n",
    "\n",
    "                true.append(target_[:, 0].cpu().detach().numpy())\n",
    "                pred.append(out[:, -1, 0].cpu().detach().numpy())\n",
    "\n",
    "            all_results['MAE'].append(mean_absolute_error(true, pred))\n",
    "            all_results['MSE'].append(mean_squared_error(true, pred))\n",
    "            all_results['R2'].append(r2_score(true, pred))\n",
    "\n",
    "        # results['Train_MAE'].append(mean_absolute_error(Y_train[:, target], train_preds))\n",
    "        # results['Train_MSE'].append(mean_squared_error(Y_train[:, target], train_preds))\n",
    "        # results['Train_R2'].append(r2_score(Y_train[:, target], train_preds))\n",
    "        results['Valid_MAE'].append(float(np.mean(all_results['MAE'])))\n",
    "        results['Valid_MSE'].append(float(np.mean(all_results['MSE'])))\n",
    "        results['Valid_R2'].append(float(np.mean(all_results['R2'])))\n",
    "\n",
    "    print('Training time: {:.4f}'.format(sum(tr_time)))\n",
    "\n",
    "#     for subset in ['Valid']:\n",
    "#         for f, force in enumerate(['Fx', 'Fy']):\n",
    "#             for loss in ['MAE', 'MSE', 'R2']:\n",
    "#                 scores = [results['_'.join([subset, loss])][i + f] for i in range(0, len(CELLS) * 2, 2)]\n",
    "#                 results['_'.join([subset, force, loss, 'mean'])] = np.mean(scores)\n",
    "#                 results['_'.join([subset, force, loss, 'std'])] = np.std(scores)\n",
    "\n",
    "    # Save the obtained results and its parameters into a JSON file\n",
    "    rd = {}\n",
    "    rd['id'] = params_id\n",
    "    rd['parameters'] = params\n",
    "    rd['parameters']['fit_time'] = sum(tr_time)\n",
    "    rd['parameters']['early_stopping'] = early_stopping\n",
    "    rd['results'] = dict(results)\n",
    "    \n",
    "    save_dir = os.path.join(RESULTS_PATH, DATA_ID, '{}_LSTM_{}'.format(JOINT, hs_date))\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    with open(os.path.join(save_dir, '{}_LSTM_{}_{}.json'.format(JOINT, hs_date, params_id)), 'w') as fp:\n",
    "        json.dump(rd, fp)\n",
    "    \n",
    "    print('\\n\\n')\n",
    "    del model, results, rd\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "attempt_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
