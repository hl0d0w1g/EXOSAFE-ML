{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "framed-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-mouse",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "wound-policy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained with data: 0005_19042021\n"
     ]
    }
   ],
   "source": [
    "# Number of force cells in the robotic leg\n",
    "N_CELLS = 8\n",
    "\n",
    "# Path where the results are stored\n",
    "RESULTS_PATH = '../../../../results'\n",
    "# ID of the training and test data resulting from this notebook, stored in RESULTS_PATH\n",
    "DATA_ID = '0005_19042021'\n",
    "# Number of folds in cross-validation\n",
    "CV = 6\n",
    "\n",
    "print('Model trained with data: ' + DATA_ID)\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-voluntary",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "silent-tyler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> X: (943372, 15), Y: (943372, 24)\n",
      "Test -> X: (161200, 15), Y: (161200, 24)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "X_train = np.load(os.path.join(RESULTS_PATH, DATA_ID, 'data', 'X_train_{}.npy'.format(DATA_ID)))\n",
    "X_test = np.load(os.path.join(RESULTS_PATH, DATA_ID, 'data', 'X_test_{}.npy'.format(DATA_ID)))\n",
    "Y_train = np.load(os.path.join(RESULTS_PATH, DATA_ID, 'data', 'Y_train_{}.npy'.format(DATA_ID)))\n",
    "Y_test = np.load(os.path.join(RESULTS_PATH, DATA_ID, 'data', 'Y_test_{}.npy'.format(DATA_ID)))\n",
    "\n",
    "print('Train -> X: {}, Y: {}'.format(X_train.shape, Y_train.shape))\n",
    "print('Test -> X: {}, Y: {}'.format(X_test.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "packed-receiver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> X: (104820, 15), Y: (104820, 24)\n",
      "Test -> X: (161200, 15), Y: (161200, 24)\n"
     ]
    }
   ],
   "source": [
    "# train_samples = X_train.shape[0]\n",
    "# step = int(train_samples / 100000)\n",
    "# idx = list(range(0, train_samples, step))\n",
    "# X_train = X_train[idx, :]\n",
    "# Y_train = Y_train[idx, :]\n",
    "\n",
    "# print('Train -> X: {}, Y: {}'.format(X_train.shape, Y_train.shape))\n",
    "# print('Test -> X: {}, Y: {}'.format(X_test.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "occasional-valuable",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/hl0d0w1g/data/Educación/Master Ing de la Informacion para la Salud/Master Thesis/EXOSAFE-ML/venv/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 161.9432\n",
      "Train Fx MAE: 6.5724 ± 2.0666\n",
      "Train Fx MSE: 93.3628 ± 52.7520\n",
      "Train Fx R2: 0.6768 ± 0.1153\n",
      "Train Fy MAE: 7.1481 ± 4.1721\n",
      "Train Fy MSE: 128.9137 ± 122.1639\n",
      "Train Fy R2: 0.4441 ± 0.1707\n",
      "Train Fz MAE: 9.4273 ± 2.6308\n",
      "Train Fz MSE: 179.2909 ± 93.4021\n",
      "Train Fz R2: 0.6923 ± 0.1257\n",
      "Test Fx MAE: 10.9019 ± 3.8761\n",
      "Test Fx MSE: 257.3233 ± 175.3165\n",
      "Test Fx R2: 0.2184 ± 0.1608\n",
      "Test Fy MAE: 9.9425 ± 6.5834\n",
      "Test Fy MSE: 321.1926 ± 391.1755\n",
      "Test Fy R2: 0.0735 ± 0.1677\n",
      "Test Fz MAE: 16.3788 ± 7.1936\n",
      "Test Fz MSE: 644.5339 ± 641.5028\n",
      "Test Fz R2: 0.1875 ± 0.1511\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'booster': 'gbtree', \n",
    "    'eta': 0.3, \n",
    "#     'gamma': 0.5, \n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.75,\n",
    "#     'lambda': 0.8,\n",
    "    'nthread': 8,\n",
    "    'seed': 0\n",
    "}\n",
    "\n",
    "results = defaultdict(list)\n",
    "\n",
    "tr_time = []\n",
    "for target in range(Y_train.shape[1]):\n",
    "\n",
    "    dtrain = xgb.DMatrix(data=X_train, label=Y_train[:, target])\n",
    "    dtest = xgb.DMatrix(data=X_test, label=Y_test[:, target])\n",
    "\n",
    "    callbacks = [xgb.callback.EarlyStopping(rounds=50, metric_name='rmse', maximize=False, save_best=True)]\n",
    "    \n",
    "    t_start = time.time()\n",
    "    model = xgb.train(params, dtrain, num_boost_round=100, evals=[(dtest, 'rmse')], callbacks=callbacks, verbose_eval=False)\n",
    "    tr_time.append(time.time() - t_start)\n",
    "    \n",
    "    train_preds = model.predict(dtrain)\n",
    "    test_preds = model.predict(dtest)\n",
    "\n",
    "    results['Train_MAE'].append(mean_absolute_error(Y_train[:, target], train_preds))\n",
    "    results['Train_MSE'].append(mean_squared_error(Y_train[:, target], train_preds))\n",
    "    results['Train_R2'].append(r2_score(Y_train[:, target], train_preds))\n",
    "    results['Test_MAE'].append(mean_absolute_error(Y_test[:, target], test_preds))\n",
    "    results['Test_MSE'].append(mean_squared_error(Y_test[:, target], test_preds))\n",
    "    results['Test_R2'].append(r2_score(Y_test[:, target], test_preds))\n",
    "    \n",
    "print('Training time: {:.4f}'.format(sum(tr_time)))\n",
    "\n",
    "results_summary = {}\n",
    "results_summary['Training time'] = sum(tr_time)\n",
    "# Display the score mean and standard deviation of each axis\n",
    "for subset in ['Train', 'Test']:\n",
    "    for f, force in enumerate(['Fx', 'Fy', 'Fz']):\n",
    "        for loss in ['MAE', 'MSE', 'R2']:\n",
    "            scores = [results['_'.join([subset, loss])][i + f] for i in range(0, N_CELLS * 3, 3)]\n",
    "            print(' '.join([subset, force, loss]) + ': {:.4f} ± {:.4f}'.format(np.mean(scores), np.std(scores)))\n",
    "            results_summary[' '.join([subset, force, loss])] = '{:.4f} ± {:.4f}'.format(np.mean(scores), np.std(scores))\n",
    "            \n",
    "results_ls.append(results_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "usual-rover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training time</th>\n",
       "      <th>Train Fx MAE</th>\n",
       "      <th>Train Fx MSE</th>\n",
       "      <th>Train Fx R2</th>\n",
       "      <th>Train Fy MAE</th>\n",
       "      <th>Train Fy MSE</th>\n",
       "      <th>Train Fy R2</th>\n",
       "      <th>Train Fz MAE</th>\n",
       "      <th>Train Fz MSE</th>\n",
       "      <th>Train Fz R2</th>\n",
       "      <th>Test Fx MAE</th>\n",
       "      <th>Test Fx MSE</th>\n",
       "      <th>Test Fx R2</th>\n",
       "      <th>Test Fy MAE</th>\n",
       "      <th>Test Fy MSE</th>\n",
       "      <th>Test Fy R2</th>\n",
       "      <th>Test Fz MAE</th>\n",
       "      <th>Test Fz MSE</th>\n",
       "      <th>Test Fz R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>161.943248</td>\n",
       "      <td>6.5724 ± 2.0666</td>\n",
       "      <td>93.3628 ± 52.7520</td>\n",
       "      <td>0.6768 ± 0.1153</td>\n",
       "      <td>7.1481 ± 4.1721</td>\n",
       "      <td>128.9137 ± 122.1639</td>\n",
       "      <td>0.4441 ± 0.1707</td>\n",
       "      <td>9.4273 ± 2.6308</td>\n",
       "      <td>179.2909 ± 93.4021</td>\n",
       "      <td>0.6923 ± 0.1257</td>\n",
       "      <td>10.9019 ± 3.8761</td>\n",
       "      <td>257.3233 ± 175.3165</td>\n",
       "      <td>0.2184 ± 0.1608</td>\n",
       "      <td>9.9425 ± 6.5834</td>\n",
       "      <td>321.1926 ± 391.1755</td>\n",
       "      <td>0.0735 ± 0.1677</td>\n",
       "      <td>16.3788 ± 7.1936</td>\n",
       "      <td>644.5339 ± 641.5028</td>\n",
       "      <td>0.1875 ± 0.1511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Training time     Train Fx MAE       Train Fx MSE      Train Fx R2  \\\n",
       "0     161.943248  6.5724 ± 2.0666  93.3628 ± 52.7520  0.6768 ± 0.1153   \n",
       "\n",
       "      Train Fy MAE         Train Fy MSE      Train Fy R2     Train Fz MAE  \\\n",
       "0  7.1481 ± 4.1721  128.9137 ± 122.1639  0.4441 ± 0.1707  9.4273 ± 2.6308   \n",
       "\n",
       "         Train Fz MSE      Train Fz R2       Test Fx MAE          Test Fx MSE  \\\n",
       "0  179.2909 ± 93.4021  0.6923 ± 0.1257  10.9019 ± 3.8761  257.3233 ± 175.3165   \n",
       "\n",
       "        Test Fx R2      Test Fy MAE          Test Fy MSE       Test Fy R2  \\\n",
       "0  0.2184 ± 0.1608  9.9425 ± 6.5834  321.1926 ± 391.1755  0.0735 ± 0.1677   \n",
       "\n",
       "        Test Fz MAE          Test Fz MSE       Test Fz R2  \n",
       "0  16.3788 ± 7.1936  644.5339 ± 641.5028  0.1875 ± 0.1511  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-terminology",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
