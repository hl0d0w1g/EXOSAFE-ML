{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gisSEwlud_Yn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "from time import strftime\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import ParameterGrid, cross_validate\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.utils.io import Tee\n",
    "\n",
    "# Redirect all the outputs messages to the terminal and to a log file\n",
    "logs_dir = './logs'\n",
    "logfilename = logs_dir + strftime('/ipython_%Y-%m-%d_%H:%M:%S') + '.log' \n",
    "if not os.path.exists(logs_dir):\n",
    "    os.makedirs(logs_dir)\n",
    "    \n",
    "sys.stdout = open('/dev/stdout', 'w')\n",
    "Tee(logfilename, mode='w', channel='stdout')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of force cells in the robotic leg\n",
    "N_CELLS = 8\n",
    "\n",
    "# Path where the results are stored\n",
    "RESULTS_PATH = '../../../../results'\n",
    "# ID of the training and validation data resulting from this notebook, stored in RESULTS_PATH\n",
    "DATA_ID = '0005_19042021'\n",
    "# Number of folds for cross-validation\n",
    "CV = 6\n",
    "\n",
    "print('Model training with data: ' + DATA_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost hyperparameters search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters search date\n",
    "hs_date = '20042021'\n",
    "\n",
    "# Parameters grid\n",
    "param_grid = {\n",
    "    'objective': ['reg:squarederror'],\n",
    "    'booster': ['gbtree'], \n",
    "    'eta': [0.3, 0.4, 0.5], \n",
    "    'gamma': [0.05, 0.01, 0.005], \n",
    "    'subsample': [0.5, 0.75, 1],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'lambda': [0, 1, 2],\n",
    "    'nthread': [8],\n",
    "    'seed': [0]\n",
    "}\n",
    "\n",
    "\n",
    "param_grid_ls = list(ParameterGrid(param_grid))\n",
    "random.shuffle(param_grid_ls)\n",
    "param_grid_len = len(param_grid_ls)\n",
    "print('Number of parameters combinations: {}'.format(param_grid_len))\n",
    "\n",
    "for idx, params in enumerate(param_grid_ls):\n",
    "    params_id = ''.join(random.choices(string.ascii_uppercase + string.digits, k=10))\n",
    "    print('Parameters ({}) {}/{}  -  {}'.format(params_id, idx + 1, param_grid_len, strftime('%Y-%m-%d %H:%M:%S')))\n",
    "    print(params)\n",
    "    \n",
    "    # Train the model with cross-validation\n",
    "    cv_results = defaultdict(list)\n",
    "    for fold_id in range(CV):\n",
    "        print('Fold {}'.format(fold_id + 1))\n",
    "        \n",
    "        # Load data\n",
    "        X_train = np.load(os.path.join(RESULTS_PATH, DATA_ID, 'data', 'X_train_cv{}_{}.npy'.format(fold_id + 1, DATA_ID)))\n",
    "        X_valid = np.load(os.path.join(RESULTS_PATH, DATA_ID, 'data', 'X_valid_cv{}_{}.npy'.format(fold_id + 1, DATA_ID)))\n",
    "        Y_train = np.load(os.path.join(RESULTS_PATH, DATA_ID, 'data', 'Y_train_cv{}_{}.npy'.format(fold_id + 1, DATA_ID)))\n",
    "        Y_valid = np.load(os.path.join(RESULTS_PATH, DATA_ID, 'data', 'Y_valid_cv{}_{}.npy'.format(fold_id + 1, DATA_ID)))\n",
    "        \n",
    "        results = defaultdict(list)\n",
    "        tr_time = []\n",
    "        for target in range(Y_train.shape[1]):\n",
    "\n",
    "            dtrain = xgb.DMatrix(data=X_train, label=Y_train[:, target])\n",
    "            dvalid = xgb.DMatrix(data=X_valid, label=Y_valid[:, target])\n",
    "\n",
    "            callbacks = [xgb.callback.EarlyStopping(rounds=5, metric_name='rmse', maximize=False, save_best=True)]\n",
    "\n",
    "            t_start = time.time()\n",
    "            model = xgb.train(params, dtrain, evals=[(dvalid, 'rmse')], callbacks=callbacks, verbose_eval=False)\n",
    "            tr_time.append(time.time() - t_start)\n",
    "\n",
    "            train_preds = model.predict(dtrain)\n",
    "            valid_preds = model.predict(dvalid)\n",
    "\n",
    "            results['Train_MAE'].append(mean_absolute_error(Y_train[:, target], train_preds))\n",
    "            results['Train_MSE'].append(mean_squared_error(Y_train[:, target], train_preds))\n",
    "            results['Train_R2'].append(r2_score(Y_train[:, target], train_preds))\n",
    "            results['Valid_MAE'].append(mean_absolute_error(Y_valid[:, target], valid_preds))\n",
    "            results['Valid_MSE'].append(mean_squared_error(Y_valid[:, target], valid_preds))\n",
    "            results['Valid_R2'].append(r2_score(Y_valid[:, target], valid_preds))\n",
    "\n",
    "        cv_results['fit_time'].append(sum(tr_time))\n",
    "        print('Training time: {:.4f}'.format(cv_results['fit_time'][-1]))\n",
    "\n",
    "        for subset in ['Train', 'Valid']:\n",
    "            for f, force in enumerate(['Fx', 'Fy', 'Fz']):\n",
    "                for loss in ['MAE', 'MSE', 'R2']:\n",
    "                    scores = [results['_'.join([subset, loss])][i + f] for i in range(0, N_CELLS * 3, 3)]\n",
    "                    cv_results['_'.join([subset, force, loss, 'mean'])].append(np.mean(scores))\n",
    "                    cv_results['_'.join([subset, force, loss, 'std'])].append(np.std(scores))\n",
    "            \n",
    "    # Save the obtained results and its parameters into a JSON file\n",
    "    rd = {}\n",
    "    rd['id'] = params_id\n",
    "    rd['parameters'] = params\n",
    "    rd['cv_results'] = dict(cv_results)\n",
    "    \n",
    "    save_dir = os.path.join(RESULTS_PATH, DATA_ID, 'XGB_{}'.format(hs_date))\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    with open(os.path.join(save_dir, 'XGB_{}_{}.json'.format(hs_date, params_id)), 'w') as fp:\n",
    "        json.dump(rd, fp)\n",
    "    \n",
    "    print('\\n\\n')\n",
    "    del model, results, cv_results, rd\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "attempt_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
