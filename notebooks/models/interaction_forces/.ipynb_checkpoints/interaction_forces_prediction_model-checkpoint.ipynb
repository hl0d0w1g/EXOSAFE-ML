{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gisSEwlud_Yn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "from time import strftime\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from IPython.utils.io import Tee\n",
    "\n",
    "# Redirect all the outputs messages to the terminal and to a log file\n",
    "logs_dir = './logs'\n",
    "logfilename = logs_dir + strftime('/ipython_%Y-%m-%d_%H:%M:%S') + '.log' \n",
    "if not os.path.exists(logs_dir):\n",
    "    os.makedirs(logs_dir)\n",
    "    \n",
    "sys.stdout = open('/dev/stdout', 'w')\n",
    "Tee(logfilename, mode='w', channel='stdout')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training with data: 0003_08042021\n"
     ]
    }
   ],
   "source": [
    "# Path where the data is stored\n",
    "SOURCE_PATH = '../../../data'\n",
    "# Directory inside SOURCE_PATH where the derived data is stored\n",
    "DERIVED_DATA_DIR = '/derived_data'\n",
    "# Experiment params\n",
    "DATE_EXPERIMENT = '24022021'\n",
    "\n",
    "# Number of force cells in the robotic leg\n",
    "N_CELLS = 8\n",
    "\n",
    "# Experiment params\n",
    "DATA_ID = '0003_08042021'\n",
    "\n",
    "print('Model training with data: ' + DATA_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train: (196835, 15), Y train: (196835, 24)\n",
      "X test: (71711, 15), Y test: (71711, 24)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load(os.path.join(SOURCE_PATH + DERIVED_DATA_DIR, DATE_EXPERIMENT, 'X_train_' + DATA_ID + '.npy'))\n",
    "X_test = np.load(os.path.join(SOURCE_PATH + DERIVED_DATA_DIR, DATE_EXPERIMENT, 'X_test_' + DATA_ID + '.npy'))\n",
    "Y_train = np.load(os.path.join(SOURCE_PATH + DERIVED_DATA_DIR, DATE_EXPERIMENT, 'Y_train_' + DATA_ID + '.npy'))\n",
    "Y_test = np.load(os.path.join(SOURCE_PATH + DERIVED_DATA_DIR, DATE_EXPERIMENT, 'Y_test_' + DATA_ID + '.npy'))\n",
    "\n",
    "print('X train: {}, Y train: {}'.format(X_train.shape, Y_train.shape))\n",
    "print('X test: {}, Y test: {}'.format(X_test.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters search\n",
    "param_grid = {\n",
    "    'n_estimators': [10],\n",
    "    'criterion': ['mae', 'mse'],\n",
    "    'max_depth': [2, 5, 10, None],\n",
    "}\n",
    "print('Number of parameters combinations: {}'.format(len(list(ParameterGrid(param_grid)))))\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor(random_state=0, verbose=1)\n",
    "\n",
    "cv = GridSearchCV(rf, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, pre_dispatch=8, verbose=1)\n",
    "cv.fit(X_train, Y_train)\n",
    "\n",
    "print('Best params: {}'.format(cv.best_params_))\n",
    "\n",
    "# Save the model\n",
    "dump(cv.best_estimator_, os.path.join(SOURCE_PATH + DERIVED_DATA_DIR, DATE_EXPERIMENT, 'model_' + DATA_ID + '.joblib')) \n",
    "model = cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 10.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../../../data/derived_data/24022021/model_0003_08042021.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=0, n_jobs=-1, verbose=1)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Save the model\n",
    "dump(model, os.path.join(SOURCE_PATH + DERIVED_DATA_DIR, DATE_EXPERIMENT, 'model_' + DATA_ID + '.joblib')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:   18.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Fx MAE: 9.4044 ± 2.8857\n",
      "Train Fx MSE: 182.2424 ± 119.3611\n",
      "Train Fx R2: 0.5802 ± 0.0614\n",
      "Train Fy MAE: 8.2783 ± 5.3926\n",
      "Train Fy MSE: 204.3028 ± 220.8775\n",
      "Train Fy R2: 0.4743 ± 0.1304\n",
      "Train Fz MAE: 12.6520 ± 4.4852\n",
      "Train Fz MSE: 345.3635 ± 264.2377\n",
      "Train Fz R2: 0.5795 ± 0.0906\n",
      "Test Fx MAE: 12.2157 ± 3.8706\n",
      "Test Fx MSE: 347.5893 ± 239.3705\n",
      "Test Fx R2: -0.2756 ± 0.2874\n",
      "Test Fy MAE: 12.3361 ± 9.1578\n",
      "Test Fy MSE: 529.0750 ± 723.1517\n",
      "Test Fy R2: -0.1454 ± 0.4550\n",
      "Test Fz MAE: 16.0123 ± 5.7524\n",
      "Test Fz MSE: 623.6688 ± 491.2103\n",
      "Test Fz R2: -0.7265 ± 0.8100\n"
     ]
    }
   ],
   "source": [
    "train_preds = model.predict(X_train)\n",
    "test_preds = model.predict(X_test)\n",
    "\n",
    "results = {\n",
    "    'Train': {\n",
    "        'MAE': mean_absolute_error(Y_train, train_preds, multioutput='raw_values'),\n",
    "        'MSE': mean_squared_error(Y_train, train_preds, multioutput='raw_values'),\n",
    "        'R2': r2_score(Y_train, train_preds, multioutput='raw_values')\n",
    "    },\n",
    "    'Test': {\n",
    "        'MAE': mean_absolute_error(Y_test, test_preds, multioutput='raw_values'),\n",
    "        'MSE': mean_squared_error(Y_test, test_preds, multioutput='raw_values'),\n",
    "        'R2': r2_score(Y_test, test_preds, multioutput='raw_values')\n",
    "    }       \n",
    "    \n",
    "}\n",
    "\n",
    "# Display the score for each axis of each force cell\n",
    "# for subset in ['Train', 'Test']:\n",
    "#     for f, force in enumerate(['Fx', 'Fy', 'Fz']):\n",
    "#         for c in range(N_CELLS):\n",
    "#             for loss in ['MAE', 'MSE', 'R2']:\n",
    "#                 scores = [results[subset][loss][i + f] for i in range(0, N_CELLS * 3, 3)]\n",
    "#                 print('{} {}{}{} {}: {:.4f}'.format(subset, force[0], c + 1, force[-1], loss, scores[c]))\n",
    "            \n",
    "print('\\n')\n",
    "\n",
    "# Display the score mean and standard deviation of each axis\n",
    "for subset in ['Train', 'Test']:\n",
    "    for f, force in enumerate(['Fx', 'Fy', 'Fz']):\n",
    "        for loss in ['MAE', 'MSE', 'R2']:\n",
    "            scores = [results[subset][loss][i + f] for i in range(0, N_CELLS * 3, 3)]\n",
    "            print(' '.join([subset, force, loss]) + ': {:.4f} ± {:.4f}'.format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7KiYjCavJo5x"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "attempt_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
