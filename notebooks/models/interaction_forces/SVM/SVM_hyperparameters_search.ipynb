{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gisSEwlud_Yn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "from time import strftime\n",
    "from joblib import dump, load\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import ParameterGrid, cross_validate\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.utils.io import Tee\n",
    "\n",
    "# Redirect all the outputs messages to the terminal and to a log file\n",
    "logs_dir = './logs'\n",
    "logfilename = logs_dir + strftime('/ipython_%Y-%m-%d_%H:%M:%S') + '.log' \n",
    "if not os.path.exists(logs_dir):\n",
    "    os.makedirs(logs_dir)\n",
    "    \n",
    "sys.stdout = open('/dev/stdout', 'w')\n",
    "Tee(logfilename, mode='w', channel='stdout')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOINT = 'Knee'\n",
    "FORCE_CELLS_PER_JOINT = {\n",
    "    'Hip': [5, 6],\n",
    "    'Knee': [3, 4, 7, 8],\n",
    "    'Ankle': [1, 2]\n",
    "}\n",
    "\n",
    "CELLS = FORCE_CELLS_PER_JOINT[JOINT]\n",
    "\n",
    "# Path where the results are stored\n",
    "RESULTS_PATH = '../../../../results'\n",
    "# ID of the training and validation data resulting from this notebook, stored in RESULTS_PATH\n",
    "DATA_ID = '0010_09082021'\n",
    "# Number of folds for cross-validation\n",
    "CV = 6\n",
    "\n",
    "print('Model training with data: ' + DATA_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine hyperparameters search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters search date\n",
    "hs_date = '24082021'\n",
    "\n",
    "# Parameters grid\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'C': [0.2, 0.3, 0.5, 0.8, 1.0, 1.2],\n",
    "    'epsilon': [0.1, 0.2, 0.3, 0.5, 0.7, 0.9],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "param_grid_ls = list(ParameterGrid(param_grid))\n",
    "random.shuffle(param_grid_ls)\n",
    "param_grid_len = len(param_grid_ls)\n",
    "print('Number of parameters combinations: {}'.format(param_grid_len))\n",
    "\n",
    "for idx, params in enumerate(param_grid_ls):\n",
    "    print(strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    params_id = ''.join(random.choices(string.ascii_uppercase + string.digits, k=10))\n",
    "    print('Parameters ({}) {}/{}'.format(params_id, idx + 1, param_grid_len))\n",
    "    print(params)\n",
    "    \n",
    "    # Train the model with cross-validation\n",
    "    cv_results = defaultdict(list)\n",
    "    for fold_id in range(CV):\n",
    "        print('Fold {}'.format(fold_id + 1))\n",
    "        \n",
    "        # Load data\n",
    "        X_train = np.load(os.path.join(RESULTS_PATH, DATA_ID, 'data', '{}_X_train_cv{}_{}.npy'.format(JOINT, fold_id + 1, DATA_ID)))\n",
    "        X_valid = np.load(os.path.join(RESULTS_PATH, DATA_ID, 'data', '{}_X_valid_cv{}_{}.npy'.format(JOINT, fold_id + 1, DATA_ID)))\n",
    "        Y_train = np.load(os.path.join(RESULTS_PATH, DATA_ID, 'data', '{}_Y_train_cv{}_{}.npy'.format(JOINT, fold_id + 1, DATA_ID)))\n",
    "        Y_valid = np.load(os.path.join(RESULTS_PATH, DATA_ID, 'data', '{}_Y_valid_cv{}_{}.npy'.format(JOINT, fold_id + 1, DATA_ID)))\n",
    "        \n",
    "        results = defaultdict(list)\n",
    "        tr_time = []\n",
    "        \n",
    "        # Setup the model\n",
    "        model = MultiOutputRegressor(SVR(**params, verbose=0), n_jobs=-1)\n",
    "        \n",
    "        # Train the model\n",
    "        t_start = time.time()\n",
    "        model.fit(X_train, Y_train)\n",
    "        t_end = time.time()\n",
    "        \n",
    "        cv_results['fit_time'].append(t_end - t_start)\n",
    "        print('Training time: {:.4f}'.format(cv_results['fit_time'][-1]))\n",
    "        \n",
    "        # Get the scores\n",
    "        train_preds = model.predict(X_train)\n",
    "        valid_preds = model.predict(X_valid)\n",
    "\n",
    "        results = {\n",
    "            'Train': {\n",
    "                'MAE': mean_absolute_error(Y_train, train_preds, multioutput='raw_values'),\n",
    "                'MSE': mean_squared_error(Y_train, train_preds, multioutput='raw_values'),\n",
    "                'R2': r2_score(Y_train, train_preds, multioutput='raw_values')\n",
    "            },\n",
    "            'Valid': {\n",
    "                'MAE': mean_absolute_error(Y_valid, valid_preds, multioutput='raw_values'),\n",
    "                'MSE': mean_squared_error(Y_valid, valid_preds, multioutput='raw_values'),\n",
    "                'R2': r2_score(Y_valid, valid_preds, multioutput='raw_values')\n",
    "            }       \n",
    "\n",
    "        }\n",
    "        \n",
    "        for subset in ['Train', 'Valid']:\n",
    "            for f, force in enumerate(['Fx', 'Fy']):\n",
    "                for loss in ['MAE', 'MSE', 'R2']:\n",
    "                    scores = [results[subset][loss][i + f] for i in range(0, len(CELLS) * 2, 2)]\n",
    "                    cv_results['_'.join([subset, force, loss, 'mean'])].append(np.mean(scores))\n",
    "                    cv_results['_'.join([subset, force, loss, 'std'])].append(np.std(scores))\n",
    "                    \n",
    "#         for target in range(Y_train.shape[1]):\n",
    "\n",
    "#             # Setup the model\n",
    "#             model = SVR(**params, verbose=0)\n",
    "            \n",
    "#             t_start = time.time()\n",
    "#             model.fit(X_train, Y_train[:, target])\n",
    "#             tr_time.append(time.time() - t_start)\n",
    "\n",
    "#             # Get the scores\n",
    "#             train_preds = model.predict(X_train)\n",
    "#             valid_preds = model.predict(X_valid)\n",
    "\n",
    "#             results['Train_MAE'].append(mean_absolute_error(Y_train[:, target], train_preds))\n",
    "#             results['Train_MSE'].append(mean_squared_error(Y_train[:, target], train_preds))\n",
    "#             results['Train_R2'].append(r2_score(Y_train[:, target], train_preds))\n",
    "#             results['Valid_MAE'].append(mean_absolute_error(Y_valid[:, target], valid_preds))\n",
    "#             results['Valid_MSE'].append(mean_squared_error(Y_valid[:, target], valid_preds))\n",
    "#             results['Valid_R2'].append(r2_score(Y_valid[:, target], valid_preds))\n",
    "\n",
    "#         cv_results['fit_time'].append(sum(tr_time))\n",
    "#         print('Training time: {:.4f}'.format(cv_results['fit_time'][-1]))\n",
    "        \n",
    "#         for subset in ['Train', 'Valid']:\n",
    "#             for f, force in enumerate(['Fx', 'Fy']):\n",
    "#                 for loss in ['MAE', 'MSE', 'R2']:\n",
    "#                     scores = [results['_'.join([subset, loss])][i + f] for i in range(0, len(CELLS) * 2, 2)]\n",
    "#                     cv_results['_'.join([subset, force, loss, 'mean'])].append(np.mean(scores))\n",
    "#                     cv_results['_'.join([subset, force, loss, 'std'])].append(np.std(scores))\n",
    "            \n",
    "    # Save the obtained results and its parameters into a JSON file\n",
    "    rd = {}\n",
    "    rd['id'] = params_id\n",
    "    rd['parameters'] = params\n",
    "    rd['cv_results'] = dict(cv_results)\n",
    "    \n",
    "    save_dir = os.path.join(RESULTS_PATH, DATA_ID, '{}_SVM_{}'.format(JOINT, hs_date))\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    with open(os.path.join(save_dir, '{}_SVM_{}_{}.json'.format(JOINT, hs_date, params_id)), 'w') as fp:\n",
    "        json.dump(rd, fp)\n",
    "    \n",
    "    print('\\n\\n')\n",
    "    del model, results, cv_results, rd\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where the results are stored\n",
    "RESULTS_PATH = '../../../../results'\n",
    "\n",
    "# Hyperparameters search date\n",
    "hs_date = '24082021'\n",
    "\n",
    "# Parameters grid\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'C': [0.2, 0.3, 0.5, 0.8, 1.0, 1.2],\n",
    "    'epsilon': [0.1, 0.2, 0.3, 0.5, 0.7, 0.9],\n",
    "}\n",
    "\n",
    "param_grid_ls = list(ParameterGrid(param_grid))\n",
    "random.shuffle(param_grid_ls)\n",
    "param_grid_len = len(param_grid_ls)\n",
    "print('Number of parameters combinations: {}'.format(param_grid_len))\n",
    "        \n",
    "FORCE_CELLS_PER_JOINT = {\n",
    "    'Hip': [5, 6],\n",
    "    'Knee': [3, 4, 7, 8],\n",
    "    'Ankle': [1, 2]\n",
    "}\n",
    "\n",
    "cv_data_id = {\n",
    "    '0010_09082021': 6,\n",
    "    '0011_09082021': 4,\n",
    "    '0012_09082021': 6,\n",
    "    '0013_09082021': 4,\n",
    "}\n",
    "\n",
    "\n",
    "for DATA_ID, CV in cv_data_id.items():\n",
    "    print('Model training with data: ' + DATA_ID)\n",
    "\n",
    "    for JOINT in ['Hip', 'Knee', 'Ankle']:\n",
    "        CELLS = FORCE_CELLS_PER_JOINT[JOINT]\n",
    "\n",
    "        for idx, params in enumerate(param_grid_ls):\n",
    "            print(strftime('%Y-%m-%d %H:%M:%S'))\n",
    "            params_id = ''.join(random.choices(string.ascii_uppercase + string.digits, k=10))\n",
    "            print('Parameters ({}) {}/{}'.format(params_id, idx + 1, param_grid_len))\n",
    "            print(params)\n",
    "\n",
    "            # Train the model with cross-validation\n",
    "            cv_results = defaultdict(list)\n",
    "            for fold_id in range(CV):\n",
    "                print('Fold {}'.format(fold_id + 1))\n",
    "\n",
    "                # Load data\n",
    "                X_train = np.load(os.path.join(RESULTS_PATH, DATA_ID, 'data', '{}_X_train_cv{}_{}.npy'.format(JOINT, fold_id + 1, DATA_ID)))\n",
    "                X_valid = np.load(os.path.join(RESULTS_PATH, DATA_ID, 'data', '{}_X_valid_cv{}_{}.npy'.format(JOINT, fold_id + 1, DATA_ID)))\n",
    "                Y_train = np.load(os.path.join(RESULTS_PATH, DATA_ID, 'data', '{}_Y_train_cv{}_{}.npy'.format(JOINT, fold_id + 1, DATA_ID)))\n",
    "                Y_valid = np.load(os.path.join(RESULTS_PATH, DATA_ID, 'data', '{}_Y_valid_cv{}_{}.npy'.format(JOINT, fold_id + 1, DATA_ID)))\n",
    "\n",
    "                results = defaultdict(list)\n",
    "                tr_time = []\n",
    "\n",
    "                # Setup the model\n",
    "                model = MultiOutputRegressor(SVR(**params, verbose=0), n_jobs=-1)\n",
    "\n",
    "                # Train the model\n",
    "                t_start = time.time()\n",
    "                model.fit(X_train, Y_train)\n",
    "                t_end = time.time()\n",
    "\n",
    "                cv_results['fit_time'].append(t_end - t_start)\n",
    "                print('Training time: {:.4f}'.format(cv_results['fit_time'][-1]))\n",
    "\n",
    "                # Get the scores\n",
    "                train_preds = model.predict(X_train)\n",
    "                valid_preds = model.predict(X_valid)\n",
    "\n",
    "                results = {\n",
    "                    'Train': {\n",
    "                        'MAE': mean_absolute_error(Y_train, train_preds, multioutput='raw_values'),\n",
    "                        'MSE': mean_squared_error(Y_train, train_preds, multioutput='raw_values'),\n",
    "                        'R2': r2_score(Y_train, train_preds, multioutput='raw_values')\n",
    "                    },\n",
    "                    'Valid': {\n",
    "                        'MAE': mean_absolute_error(Y_valid, valid_preds, multioutput='raw_values'),\n",
    "                        'MSE': mean_squared_error(Y_valid, valid_preds, multioutput='raw_values'),\n",
    "                        'R2': r2_score(Y_valid, valid_preds, multioutput='raw_values')\n",
    "                    }       \n",
    "\n",
    "                }\n",
    "\n",
    "                for subset in ['Train', 'Valid']:\n",
    "                    for f, force in enumerate(['Fx', 'Fy']):\n",
    "                        for loss in ['MAE', 'MSE', 'R2']:\n",
    "                            scores = [results[subset][loss][i + f] for i in range(0, len(CELLS) * 2, 2)]\n",
    "                            cv_results['_'.join([subset, force, loss, 'mean'])].append(np.mean(scores))\n",
    "                            cv_results['_'.join([subset, force, loss, 'std'])].append(np.std(scores))\n",
    "\n",
    "            # Save the obtained results and its parameters into a JSON file\n",
    "            rd = {}\n",
    "            rd['id'] = params_id\n",
    "            rd['parameters'] = params\n",
    "            rd['cv_results'] = dict(cv_results)\n",
    "\n",
    "            save_dir = os.path.join(RESULTS_PATH, DATA_ID, '{}_SVM_{}'.format(JOINT, hs_date))\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "\n",
    "            with open(os.path.join(save_dir, '{}_SVM_{}_{}.json'.format(JOINT, hs_date, params_id)), 'w') as fp:\n",
    "                json.dump(rd, fp)\n",
    "\n",
    "            print('\\n\\n')\n",
    "            del model, results, cv_results, rd\n",
    "            gc.collect()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "attempt_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
