{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gisSEwlud_Yn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "from time import strftime\n",
    "from joblib import dump, load\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import ParameterGrid, cross_validate\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.utils.io.Tee at 0x7f40283b66a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.utils.io import Tee\n",
    "\n",
    "# Redirect all the outputs messages to the terminal and to a log file\n",
    "logs_dir = './logs'\n",
    "logfilename = logs_dir + strftime('/ipython_%Y-%m-%d_%H:%M:%S') + '.log' \n",
    "if not os.path.exists(logs_dir):\n",
    "    os.makedirs(logs_dir)\n",
    "    \n",
    "sys.stdout = open('/dev/stdout', 'w')\n",
    "Tee(logfilename, mode='w', channel='stdout')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOINT = 'Ankle'\n",
    "FORCE_CELLS_PER_JOINT = {\n",
    "    'Hip': [5, 6],\n",
    "    'Knee': [3, 4, 7, 8],\n",
    "    'Ankle': [1, 2]\n",
    "}\n",
    "\n",
    "CELLS = FORCE_CELLS_PER_JOINT[JOINT]\n",
    "\n",
    "# Path where the results are stored\n",
    "RESULTS_PATH = '../../../../results'\n",
    "# ID of the training and validation data resulting from this notebook, stored in RESULTS_PATH\n",
    "DATA_ID = '0013_09082021'\n",
    "# Number of folds for cross-validation\n",
    "CV = 4\n",
    "\n",
    "print('Model training with data: ' + DATA_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest hyperparameters search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters search date\n",
    "hs_date = '13082021'\n",
    "\n",
    "# Parameters grid\n",
    "param_grid = {\n",
    "    'n_estimators': [700, 1000, 2500],\n",
    "    'max_depth': [13, 15, 20, 30, 50],\n",
    "    'max_features': [0.1, 0.2, 0.3, 0.5, 0.7],\n",
    "    'min_samples_leaf': [0.001, 0.0001, 0.00001],\n",
    "    'min_samples_split': [0.001, 0.0001, 0.00001]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "param_grid_ls = list(ParameterGrid(param_grid))\n",
    "random.shuffle(param_grid_ls)\n",
    "param_grid_len = len(param_grid_ls)\n",
    "print('Number of parameters combinations: {}'.format(param_grid_len))\n",
    "\n",
    "for idx, params in enumerate(param_grid_ls):\n",
    "    print(strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    params_id = ''.join(random.choices(string.ascii_uppercase + string.digits, k=10))\n",
    "    print('Parameters ({}) {}/{}'.format(params_id, idx + 1, param_grid_len))\n",
    "    print(params)\n",
    "    \n",
    "    # Train the model with cross-validation\n",
    "    cv_results = defaultdict(list)\n",
    "    for fold_id in range(CV):\n",
    "        print('Fold {}'.format(fold_id + 1))\n",
    "        \n",
    "        # Load data\n",
    "        X_train = np.load(os.path.join(RESULTS_PATH, DATA_ID, 'data', '{}_X_train_cv{}_{}.npy'.format(JOINT, fold_id + 1, DATA_ID)))\n",
    "        X_valid = np.load(os.path.join(RESULTS_PATH, DATA_ID, 'data', '{}_X_valid_cv{}_{}.npy'.format(JOINT, fold_id + 1, DATA_ID)))\n",
    "        Y_train = np.load(os.path.join(RESULTS_PATH, DATA_ID, 'data', '{}_Y_train_cv{}_{}.npy'.format(JOINT, fold_id + 1, DATA_ID)))\n",
    "        Y_valid = np.load(os.path.join(RESULTS_PATH, DATA_ID, 'data', '{}_Y_valid_cv{}_{}.npy'.format(JOINT, fold_id + 1, DATA_ID)))\n",
    "        \n",
    "        # Setup the model\n",
    "        model = RandomForestRegressor(**params, random_state=0, n_jobs=-1, verbose=0)\n",
    "        \n",
    "        # Train the model\n",
    "        t_start = time.time()\n",
    "        model.fit(X_train, Y_train)\n",
    "        t_end = time.time()\n",
    "        \n",
    "        cv_results['fit_time'].append(t_end - t_start)\n",
    "        \n",
    "        # Get the scores\n",
    "        train_preds = model.predict(X_train)\n",
    "        valid_preds = model.predict(X_valid)\n",
    "\n",
    "        results = {\n",
    "            'Train': {\n",
    "                'MAE': mean_absolute_error(Y_train, train_preds, multioutput='raw_values'),\n",
    "                'MSE': mean_squared_error(Y_train, train_preds, multioutput='raw_values'),\n",
    "                'R2': r2_score(Y_train, train_preds, multioutput='raw_values')\n",
    "            },\n",
    "            'Valid': {\n",
    "                'MAE': mean_absolute_error(Y_valid, valid_preds, multioutput='raw_values'),\n",
    "                'MSE': mean_squared_error(Y_valid, valid_preds, multioutput='raw_values'),\n",
    "                'R2': r2_score(Y_valid, valid_preds, multioutput='raw_values')\n",
    "            }       \n",
    "\n",
    "        }\n",
    "        \n",
    "        for subset in ['Train', 'Valid']:\n",
    "            for f, force in enumerate(['Fx', 'Fy']):\n",
    "                for loss in ['MAE', 'MSE', 'R2']:\n",
    "                    scores = [results[subset][loss][i + f] for i in range(0, len(CELLS) * 2, 2)]\n",
    "                    cv_results['_'.join([subset, force, loss, 'mean'])].append(np.mean(scores))\n",
    "                    cv_results['_'.join([subset, force, loss, 'std'])].append(np.std(scores))\n",
    "            \n",
    "    # Save the obtained results and its parameters into a JSON file\n",
    "    rd = {}\n",
    "    rd['id'] = params_id\n",
    "    rd['parameters'] = params\n",
    "    rd['cv_results'] = dict(cv_results)\n",
    "    \n",
    "    save_dir = os.path.join(RESULTS_PATH, DATA_ID, '{}_RF_{}'.format(JOINT, hs_date))\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    with open(os.path.join(save_dir, '{}_RF_{}_{}.json'.format(JOINT, hs_date, params_id)), 'w') as fp:\n",
    "        json.dump(rd, fp)\n",
    "    \n",
    "    print('\\n\\n')\n",
    "    del model, results, cv_results, rd\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "attempt_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
