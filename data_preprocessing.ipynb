{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "universal-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-burns",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "respected-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where the data is stored\n",
    "SOURCE_PATH = '../../data'\n",
    "# Directory inside SOURCE_PATH where the original data is stored\n",
    "ORIGINAL_DATA_DIR = '/original_data'\n",
    "# Directory inside SOURCE_PATH where the derived data is stored\n",
    "DERIVED_DATA_DIR = '/derived_data'\n",
    "# Directory inside SOURCE_PATH where the data resulting from this notebook is stored\n",
    "RESULTS_DIR = '/models_data/0001_16032021'\n",
    "\n",
    "# % of the data for the test set\n",
    "TEST_SIZE = 0.3\n",
    "\n",
    "# Number of force cells in the robotic leg\n",
    "N_CELLS = 8\n",
    "\n",
    "# Experiment params\n",
    "DATE = '12022021'\n",
    "N_EXPERIMENTS = 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-accident",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "basic-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotations = {\n",
    "    1: [180, 90, 0],\n",
    "    2: [180, 90, 0],\n",
    "    3: [180, 0, -90],\n",
    "    4: [0, 0, -90],\n",
    "    5: [0, 0, 0],\n",
    "    6: [0, 180, 0],\n",
    "    7: [0, 90, 0],\n",
    "    8: [0, 0, 90],\n",
    "}\n",
    "\n",
    "def rotate_vector(v, axis, angle):\n",
    "    '''\n",
    "    \n",
    "    Args:\n",
    "    - v (np.array):\n",
    "    - axis (int):\n",
    "    - angle ():\n",
    "    \n",
    "    Returns:\n",
    "    - (pd.Series):\n",
    "    '''\n",
    "    if axis == 0:\n",
    "        # X\n",
    "        v = v.dot(np.array([[1, 0, 0], [0, np.cos(np.radians(angle)), np.sin(np.radians(angle))], [0, np.sin(np.radians(angle)), np.cos(np.radians(angle))]]))\n",
    "    elif axis == 1:\n",
    "        # Y\n",
    "        v = v.dot(np.array([[np.cos(np.radians(angle)), 0, np.sin(np.radians(angle))], [0, 1, 0], [-np.sin(np.radians(angle)), 0, np.cos(np.radians(angle))]]))\n",
    "    elif axis == 2:\n",
    "        # Z\n",
    "        v = v.dot(np.array([[np.cos(np.radians(angle)), -np.sin(np.radians(angle)), 0], [np.sin(np.radians(angle)), np.cos(np.radians(angle)), 0], [0, 0, 1]]))\n",
    "    else:\n",
    "        raise ValueError('Invalid axis')\n",
    "\n",
    "    return pd.Series(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ambient-healthcare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(N_EXPERIMENTS):\n",
    "    save_dir = os.path.join(SOURCE_PATH + DERIVED_DATA_DIR, DATE, str(i + 1))\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    H3_df = pd.read_excel(SOURCE_PATH + ORIGINAL_DATA_DIR + '/0{}-'.format(i + 1) + DATE + '.xlsx', sheet_name='H3processed')\n",
    "    H3_df.to_csv(save_dir + '/H3.csv', index=False)\n",
    "    \n",
    "    leg_df = pd.read_excel(SOURCE_PATH + ORIGINAL_DATA_DIR + '/0{}-'.format(i + 1) + DATE + '.xlsx', sheet_name='Leg-Replica')\n",
    "    leg_df.to_csv(save_dir + '/leg.csv', index=False)\n",
    "    \n",
    "    forces_df = pd.read_excel(SOURCE_PATH + ORIGINAL_DATA_DIR + '/0{}-'.format(i + 1) + DATE + '.xlsx', sheet_name='ForceCells', usecols=[i for i in range(N_CELLS * 3)])\n",
    "    \n",
    "    for i in range (1, N_CELLS + 1):\n",
    "        cols = ['F{}x'.format(str(i)), 'F{}y'.format(str(i)), 'F{}z'.format(str(i))]\n",
    "        for ax in range(3):\n",
    "            forces_df[cols] = forces_df[cols].apply(lambda v: rotate_vector(v, ax, rotations[i][ax]), axis=1)\n",
    "    \n",
    "    forces_df.to_csv(save_dir + '/forces.csv', index=False)\n",
    "\n",
    "\n",
    "del H3_df, leg_df, forces_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-subscription",
   "metadata": {},
   "source": [
    "## Features and target selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "departmental-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_df_ls = []\n",
    "features_df_ls = []\n",
    "for i in range(N_EXPERIMENTS):\n",
    "    data_dir = os.path.join(SOURCE_PATH + DERIVED_DATA_DIR, DATE, str(i + 1))\n",
    "    \n",
    "    targets_df = pd.read_csv(data_dir + '/forces.csv')\n",
    "    targets_df_ls.append(target_df)\n",
    "    \n",
    "    h3_features_df = pd.read_csv(data_dir + '/H3.csv')\n",
    "    leg_features_df = pd.read_csv(data_dir + '/leg.csv')\n",
    "    features_df = pd.concat([h3_features_df, leg_features_df], axis=1)\n",
    "    features_df_ls.append(features_df)\n",
    "\n",
    "targets_df = pd.concat(targets_df_ls, axis=0)\n",
    "features_df = pd.concat(features_df_ls, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "introductory-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to manage with some typos\n",
    "features_df = features_df.rename(columns={'LankleTorque': 'LAnkleTorque', 'RankleTorque': 'RAnkleTorque'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "driving-certificate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 12\n",
      "Number of targets: 24\n"
     ]
    }
   ],
   "source": [
    "H3_LEG = 'L' # L|R\n",
    "\n",
    "features = [H3_LEG + a + m for a in ['Hip', 'Knee', 'Ankle'] for m in ['Pos', 'Vel', 'Acc', 'Torque']]\n",
    "targets = ['F' + str(i + 1) + ax for i in range(N_CELLS) for ax in ['x', 'y', 'z']]\n",
    "\n",
    "print('Number of features: {}'.format(len(features)))\n",
    "print('Number of targets: {}'.format(len(targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "superb-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_df[features]\n",
    "Y = targets_df[targets]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-concord",
   "metadata": {},
   "source": [
    "## Nulls handeling, split and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "consistent-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null values\n",
    "idx = X.notna().all(axis=1)\n",
    "X = X.loc[idx].values\n",
    "Y = target_df.loc[idx].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "educated-application",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> X: (88190, 12), Y: (88190, 24)\n",
      "Test -> X: (37796, 12), Y: (37796, 24)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=TEST_SIZE, random_state=0)\n",
    "\n",
    "print('Train -> X: {}, Y: {}'.format(X_train.shape, Y_train.shape))\n",
    "print('Test -> X: {}, Y: {}'.format(X_test.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cardiac-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_norm = scaler.transform(X_train)\n",
    "X_test_norm =  scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-bernard",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "restricted-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = SOURCE_PATH + RESULTS_DIR\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "np.save(save_dir + '/X_train.npy', X_train_norm)    \n",
    "np.save(save_dir + '/X_test.npy', X_test_norm)    \n",
    "np.save(save_dir + '/Y_train.npy', Y_train)    \n",
    "np.save(save_dir + '/Y_test.npy', Y_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-samoa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
